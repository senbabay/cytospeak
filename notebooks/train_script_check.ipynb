{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d1176c1",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c214670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import signal\n",
    "import argparse\n",
    "import yaml\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from datasets import load_dataset\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.plugins.environments import SLURMEnvironment\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor\n",
    "from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor\n",
    "from transformers.optimization import get_scheduler\n",
    "from peft import LoraConfig, get_peft_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1403e89",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c9114a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--config\", type=str, default=\"qwen2vl_config.yaml\")\n",
    "\n",
    "# mirror TrainingArguments you shared\n",
    "parser.add_argument(\"--epochs\", type=int, default=None)                     # num_train_epochs\n",
    "parser.add_argument(\"--lr\", type=float, default=None)                       # learning_rate\n",
    "parser.add_argument(\"--lr_scheduler_type\", type=str, default=None,          # lr_scheduler_type\n",
    "                    choices=[\"linear\",\"cosine\",\"cosine_with_restarts\",\"polynomial\",\"constant\",\"constant_with_warmup\"])\n",
    "parser.add_argument(\"--batch_size\", type=int, default=None)                 # per_device_train_batch_size\n",
    "parser.add_argument(\"--eval_batch_size\", type=int, default=None)            # per_device_eval_batch_size\n",
    "parser.add_argument(\"--grad_accum\", type=int, default=None)                 # gradient_accumulation_steps\n",
    "parser.add_argument(\"--weight_decay\", type=float, default=None)\n",
    "parser.add_argument(\"--logging_fraction\", type=float, default=None)         # to derive logging_steps\n",
    "parser.add_argument(\"--eval_fraction\", type=float, default=None)            # to derive eval_steps\n",
    "parser.add_argument(\"--warmup_steps\", type=int, default=None)               # optional\n",
    "parser.add_argument(\"--warmup_ratio\", type=float, default=None)             # optional, if steps not given\n",
    "\n",
    "# runtime/system\n",
    "parser.add_argument(\"--model_id\", type=str, default=None)\n",
    "parser.add_argument(\"--dataset\", type=str, default=None)\n",
    "parser.add_argument(\"--num_workers\", type=int, default=None)\n",
    "parser.add_argument(\"--precision\", type=str, default=None, choices=[\"bf16-mixed\",\"16-mixed\",\"32-true\"])\n",
    "parser.add_argument(\"--devices\", type=int, default=None)\n",
    "parser.add_argument(\"--strategy\", type=str, default=None)\n",
    "parser.add_argument(\"--seed\", type=int, default=None)\n",
    "parser.add_argument(\"--tf32\", action=\"store_true\")\n",
    "parser.add_argument(\"--no_tf32\", dest=\"tf32\", action=\"store_false\")\n",
    "parser.set_defaults(tf32=True)\n",
    "\n",
    "# logging / names / output\n",
    "parser.add_argument(\"--run_name\", type=str, default=None)\n",
    "parser.add_argument(\"--logging_dir\", type=str, default=None)\n",
    "parser.add_argument(\"--output_dir\", type=str, default=None)\n",
    "\n",
    "# GC controls (Trainer: gradient_checkpointing, kwargs)\n",
    "parser.add_argument(\"--gradient_checkpointing\", action=\"store_true\")\n",
    "parser.add_argument(\"--no_gradient_checkpointing\", dest=\"gradient_checkpointing\", action=\"store_false\")\n",
    "parser.set_defaults(gradient_checkpointing=True)\n",
    "parser.add_argument(\"--gc_use_reentrant\", action=\"store_true\")\n",
    "parser.add_argument(\"--gc_no_reentrant\", dest=\"gc_use_reentrant\", action=\"store_false\")\n",
    "parser.set_defaults(gc_use_reentrant=False)  # Qwen-friendly default\n",
    "\n",
    "# HF Hub\n",
    "parser.add_argument(\"--hub_model_id\", type=str, default=None)\n",
    "\n",
    "# ---- LoRA CLI overrides \n",
    "parser.add_argument(\"--lora_r\", type=int, default=None)\n",
    "parser.add_argument(\"--lora_alpha\", type=float, default=None)\n",
    "parser.add_argument(\"--lora_dropout\", type=float, default=None)\n",
    "parser.add_argument(\"--lora_bias\", type=str, default=None, choices=[\"none\",\"all\",\"lora_only\"])\n",
    "parser.add_argument(\"--lora_task_type\", type=str, default=None, help=\"e.g., CAUSAL_LM\")\n",
    "\n",
    "parser.add_argument(\"--lora_use_rslora\", dest=\"lora_use_rslora\", action=\"store_true\")\n",
    "parser.add_argument(\"--lora_no_use_rslora\", dest=\"lora_use_rslora\", action=\"store_false\")\n",
    "parser.set_defaults(lora_use_rslora=None)  # None = not provided on CLI\n",
    "\n",
    "parser.add_argument(\"--lora_target_modules\", type=str, default=None,\n",
    "                    help=\"Comma-separated list e.g. 'q_proj,k_proj,v_proj,o_proj,...'\")\n",
    "parser.add_argument(\"--lora_modules_to_save\", type=str, default=None,\n",
    "                    help=\"Comma-separated list e.g. 'lm_head,embed_tokens'\")\n",
    "\n",
    "parser.add_argument(\"--lora_extras_yaml\", type=str, default=None,\n",
    "                    help=\"Inline YAML/JSON dict of extra LoraConfig fields (e.g., rank_pattern)\")\n",
    "\n",
    "args = parser.parse_args([])\n",
    "\n",
    "# Load YAML and merge\n",
    "with open(args.config, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "def pick(key, default=None):\n",
    "    return getattr(args, key) if getattr(args, key) is not None else config.get(key, default)\n",
    "\n",
    "# Map your provided defaults\n",
    "epochs          = pick(\"epochs\", 3)\n",
    "lr              = pick(\"lr\", 1e-4)\n",
    "lr_scheduler    = pick(\"lr_scheduler_type\", \"linear\")\n",
    "batch_size      = pick(\"batch_size\", 1)\n",
    "eval_batch_size = pick(\"eval_batch_size\", 1)\n",
    "grad_accum      = pick(\"grad_accum\", 4)\n",
    "weight_decay    = pick(\"weight_decay\", 0.01)\n",
    "logging_frac    = pick(\"logging_fraction\", 0.10)\n",
    "eval_frac       = pick(\"eval_fraction\", 0.10)\n",
    "warmup_steps_cfg= pick(\"warmup_steps\", None)\n",
    "warmup_ratio    = pick(\"warmup_ratio\", None)  # if you decide to use ratio\n",
    "\n",
    "model_id        = pick(\"model_id\")\n",
    "dataset_name    = pick(\"dataset\")\n",
    "num_workers     = pick(\"num_workers\", 4)\n",
    "precision       = pick(\"precision\", \"bf16-mixed\")\n",
    "devices         = pick(\"devices\", 1)\n",
    "strategy        = pick(\"strategy\", \"ddp\")\n",
    "seed            = pick(\"seed\", 42)\n",
    "tf32            = args.tf32 if \"tf32\" in args else config.get(\"tf32\", True)\n",
    "\n",
    "run_name        = pick(\"run_name\", f\"trelis-chess-{lr}_lr-{epochs}_epochs-{lr_scheduler}_schedule-completions-only-annealing\")\n",
    "logging_dir     = pick(\"logging_dir\", f\"./logs/{run_name}\")\n",
    "output_dir      = pick(\"output_dir\", \"fine-tuned-model\")\n",
    "\n",
    "gradient_checkpointing = args.gradient_checkpointing if \"gradient_checkpointing\" in args else config.get(\"gradient_checkpointing\", True)\n",
    "gc_use_reentrant       = args.gc_use_reentrant if \"gc_use_reentrant\" in args else config.get(\"gc_use_reentrant\", False)\n",
    "\n",
    "hub_model_id    = pick(\"hub_model_id\", \"shenbaba/Qwen2.5-VLM-3B-chess\")\n",
    "\n",
    "# --- LoRA config (YAML + CLI overrides via pick-like behavior) ---\n",
    "lora_from_yaml = config.get(\"lora\", {}) or {}\n",
    "_default_lora = {\n",
    "    \"r\": 32,\n",
    "    \"lora_alpha\": 16,\n",
    "    \"use_rslora\": True,\n",
    "    \"target_modules\": [\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\"up_proj\",\"down_proj\",\"gate_proj\",\"mlp.0\",\"mlp.2\"],\n",
    "    \"modules_to_save\": [\"lm_head\",\"embed_tokens\"],\n",
    "    \"lora_dropout\": 0.1,\n",
    "    \"bias\": \"none\",\n",
    "    \"task_type\": \"CAUSAL_LM\",\n",
    "}\n",
    "\n",
    "def _split_csv(s):\n",
    "    return [x.strip() for x in s.split(\",\")] if s else None\n",
    "\n",
    "def pick_lora(field, default=None):\n",
    "    # CLI first\n",
    "    cli_val = getattr(args, f\"lora_{field}\", None)\n",
    "    if cli_val is not None:\n",
    "        return cli_val\n",
    "    # YAML next\n",
    "    if field in lora_from_yaml and lora_from_yaml[field] is not None:\n",
    "        return lora_from_yaml[field]\n",
    "    # Fallback\n",
    "    return _default_lora.get(field, default)\n",
    "\n",
    "lora_cfg = {\n",
    "    \"r\": pick_lora(\"r\"),\n",
    "    \"lora_alpha\": pick_lora(\"lora_alpha\"),\n",
    "    \"lora_dropout\": pick_lora(\"lora_dropout\"),\n",
    "    \"use_rslora\": pick_lora(\"use_rslora\"),\n",
    "    \"bias\": pick_lora(\"bias\"),\n",
    "    \"task_type\": pick_lora(\"task_type\"),\n",
    "    \"target_modules\": _split_csv(args.lora_target_modules)\n",
    "                        if args.lora_target_modules is not None\n",
    "                        else pick_lora(\"target_modules\"),\n",
    "    \"modules_to_save\": _split_csv(args.lora_modules_to_save)\n",
    "                        if args.lora_modules_to_save is not None\n",
    "                        else pick_lora(\"modules_to_save\"),\n",
    "}\n",
    "\n",
    "if args.lora_extras_yaml:\n",
    "    try:\n",
    "        extra = yaml.safe_load(args.lora_extras_yaml)\n",
    "        if isinstance(extra, dict):\n",
    "            lora_cfg.update(extra)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "07a36992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'r': 32,\n",
       " 'lora_alpha': 16,\n",
       " 'lora_dropout': 0.1,\n",
       " 'use_rslora': True,\n",
       " 'bias': 'none',\n",
       " 'task_type': 'CAUSAL_LM',\n",
       " 'target_modules': ['q_proj',\n",
       "  'k_proj',\n",
       "  'v_proj',\n",
       "  'o_proj',\n",
       "  'up_proj',\n",
       "  'down_proj',\n",
       "  'gate_proj',\n",
       "  'mlp.0',\n",
       "  'mlp.2'],\n",
       " 'modules_to_save': ['lm_head', 'embed_tokens']}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b5b1762",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(seed, workers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1629ff",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "edd0b904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen/Qwen2.5-VL-3B-Instruct\n",
      "Trelis/chess_pieces\n"
     ]
    }
   ],
   "source": [
    "# print model id and dataset name\n",
    "print(model_id)\n",
    "print(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e584a8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = AutoProcessor.from_pretrained(model_id, use_fast=True) # change this back to use_fast=False if you run into issues\n",
    "dataset = load_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4c94a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46a97872597f41feb040056efa294431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/48 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afce035e3b0b4cf68c7aca25920a4067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Optional: quick shrink for prototyping (same as before)\n",
    "resize_image = lambda ex: {\"image\": ex[\"image\"].resize((ex[\"image\"].width // 4, ex[\"image\"].height // 4))}\n",
    "train_dataset = dataset[\"train\"].map(resize_image)\n",
    "val_dataset   = dataset[\"test\"].map(resize_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8362fa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -----------------------\n",
    "# # Dataset wrapper for Hugging Face datasets\n",
    "# # -----------------------\n",
    "# class ChessDataset(Dataset):\n",
    "#     \"\"\"Wraps an HF dataset so it behaves like a standard PyTorch Dataset.\"\"\"\n",
    "#     def __init__(self, hf_dataset):\n",
    "#         self.dataset = hf_dataset\n",
    "#     def __len__(self):\n",
    "#         return len(self.dataset)\n",
    "#     def __getitem__(self, idx):\n",
    "#         return self.dataset[idx]\n",
    "\n",
    "# train_ds = ChessDataset(train_dataset)\n",
    "# val_ds   = ChessDataset(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bde17ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2_5_VLProcessor:\n",
       "- image_processor: Qwen2VLImageProcessorFast {\n",
       "  \"crop_size\": null,\n",
       "  \"data_format\": \"channels_first\",\n",
       "  \"default_to_square\": true,\n",
       "  \"device\": null,\n",
       "  \"do_center_crop\": null,\n",
       "  \"do_convert_rgb\": true,\n",
       "  \"do_normalize\": true,\n",
       "  \"do_rescale\": true,\n",
       "  \"do_resize\": true,\n",
       "  \"image_mean\": [\n",
       "    0.48145466,\n",
       "    0.4578275,\n",
       "    0.40821073\n",
       "  ],\n",
       "  \"image_processor_type\": \"Qwen2VLImageProcessorFast\",\n",
       "  \"image_std\": [\n",
       "    0.26862954,\n",
       "    0.26130258,\n",
       "    0.27577711\n",
       "  ],\n",
       "  \"input_data_format\": null,\n",
       "  \"max_pixels\": 12845056,\n",
       "  \"merge_size\": 2,\n",
       "  \"min_pixels\": 3136,\n",
       "  \"patch_size\": 14,\n",
       "  \"processor_class\": \"Qwen2_5_VLProcessor\",\n",
       "  \"resample\": 3,\n",
       "  \"rescale_factor\": 0.00392156862745098,\n",
       "  \"return_tensors\": null,\n",
       "  \"size\": {\n",
       "    \"longest_edge\": 12845056,\n",
       "    \"shortest_edge\": 3136\n",
       "  },\n",
       "  \"temporal_patch_size\": 2\n",
       "}\n",
       "\n",
       "- tokenizer: Qwen2TokenizerFast(name_or_path='Qwen/Qwen2.5-VL-3B-Instruct', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t151643: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151644: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151645: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151646: AddedToken(\"<|object_ref_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151647: AddedToken(\"<|object_ref_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151648: AddedToken(\"<|box_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151649: AddedToken(\"<|box_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151650: AddedToken(\"<|quad_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151651: AddedToken(\"<|quad_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151652: AddedToken(\"<|vision_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151653: AddedToken(\"<|vision_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151654: AddedToken(\"<|vision_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151655: AddedToken(\"<|image_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151656: AddedToken(\"<|video_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151657: AddedToken(\"<tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151658: AddedToken(\"</tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151659: AddedToken(\"<|fim_prefix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151660: AddedToken(\"<|fim_middle|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151661: AddedToken(\"<|fim_suffix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151662: AddedToken(\"<|fim_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151663: AddedToken(\"<|repo_name|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151664: AddedToken(\"<|file_sep|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "}\n",
       ")\n",
       "\n",
       "{\n",
       "  \"processor_class\": \"Qwen2_5_VLProcessor\"\n",
       "}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bf2a57b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# Custom collator for multimodal Qwen input\n",
    "# -----------------------\n",
    "class AssistantOnlyCollator:\n",
    "    \"\"\"\n",
    "    Formats examples into Qwen chat template:\n",
    "    - User message contains text + image placeholder.\n",
    "    - Assistant message contains only the caption (target).\n",
    "    - Masks all tokens except the assistant's answer in labels.\n",
    "    \"\"\"\n",
    "    def __init__(self, processor):\n",
    "        self.processor = processor\n",
    "\n",
    "    def __call__(self, examples):\n",
    "        texts, images, targets = [], [], []\n",
    "        for ex in examples:\n",
    "            question = \"What do you see here?\"\n",
    "            answer = ex[\"caption\"]\n",
    "            image = ex[\"image\"]\n",
    "\n",
    "            # Construct multi-turn conversation with image\n",
    "            messages = [\n",
    "                {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": question}, {\"type\": \"image\"}]},\n",
    "                {\"role\": \"assistant\", \"content\": [{\"type\": \"text\", \"text\": answer}]}\n",
    "            ]\n",
    "            text = self.processor.apply_chat_template(messages, add_generation_prompt=False)\n",
    "\n",
    "            texts.append(text.strip())\n",
    "            images.append([image])\n",
    "            targets.append(answer)\n",
    "\n",
    "        # Tokenize and pad batch\n",
    "        batch = self.processor(text=texts, images=images, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "        # Mask all tokens except the assistant's answer in labels\n",
    "        labels = batch[\"input_ids\"].clone()\n",
    "        for i, (input_ids, target) in enumerate(zip(batch[\"input_ids\"], targets)):\n",
    "            target_ids = self.processor.tokenizer(target, return_tensors=\"pt\")[\"input_ids\"][0]\n",
    "            start = self.find_subsequence(input_ids, target_ids)\n",
    "            if start is not None:\n",
    "                end = start + len(target_ids)\n",
    "                if end < len(input_ids) and input_ids[end] == self.processor.tokenizer.eos_token_id:\n",
    "                    end += 1\n",
    "                # Mask user prompt and everything after answer\n",
    "                labels[i, :start] = -100\n",
    "                labels[i, end:] = -100\n",
    "            else:\n",
    "                # If the answer sequence isn't found, mask everything to avoid corrupt loss\n",
    "                labels[i, :] = -100\n",
    "        batch[\"labels\"] = labels\n",
    "        return batch\n",
    "\n",
    "    def find_subsequence(self, seq, subseq):\n",
    "        \"\"\"Find exact subsequence match in token IDs (for locating assistant's answer).\"\"\"\n",
    "        for i in range(len(seq) - len(subseq) + 1):\n",
    "            if torch.equal(seq[i:i + len(subseq)], subseq):\n",
    "                return i\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "59745a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = AssistantOnlyCollator(processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b54dd735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steps accounting to mirror your Trainer math\n",
    "dataset_len = len(train_dataset)\n",
    "steps_per_epoch = math.ceil(dataset_len / (batch_size * max(1, grad_accum)))\n",
    "total_steps = steps_per_epoch * epochs\n",
    "\n",
    "# Fractions → concrete steps\n",
    "logging_steps = max(1, int(total_steps * float(logging_frac)))\n",
    "eval_steps    = max(1, int(total_steps * float(eval_frac)))\n",
    "\n",
    "# Warmup resolution\n",
    "if warmup_steps_cfg is not None:\n",
    "    warmup_steps = int(warmup_steps_cfg)\n",
    "elif warmup_ratio is not None:\n",
    "    warmup_steps = int(total_steps * float(warmup_ratio))\n",
    "else:\n",
    "    warmup_steps = 0  # matches your commented-out default\n",
    "\n",
    "# -----------------------\n",
    "# Dataloaders\n",
    "# -----------------------\n",
    "# Pin + persistent workers improve performance on repeated small batches\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collator,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=eval_batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=collator,\n",
    "    num_workers=max(1, num_workers // 2),\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e6192f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# Logging & checkpoints\n",
    "# -----------------------\n",
    "# Logger & callbacks (TensorBoard + step-based eval/checkpointing)\n",
    "logger = TensorBoardLogger(\n",
    "    save_dir=logging_dir,\n",
    "    name=run_name,\n",
    "    default_hp_metric=False  # prevents Lightning adding HP metric noise\n",
    ")\n",
    "ckpt_cb = ModelCheckpoint(\n",
    "    dirpath=output_dir,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_top_k=1,               # keep best model only (like save_total_limit=1)\n",
    "    every_n_train_steps=eval_steps,  # save on same cadence as eval\n",
    "    filename=\"step{step}-valloss{val_loss:.4f}\",\n",
    "    auto_insert_metric_name=False,\n",
    "    save_last=True,\n",
    ")\n",
    "lr_cb = LearningRateMonitor(logging_interval=\"step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5c14f765",
   "metadata": {},
   "outputs": [],
   "source": [
    "del QwenLoraModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7841fb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# LightningModule with LoRA-wrapped Qwen\n",
    "# -----------------------\n",
    "class QwenLoraModule(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    LightningModule wrapping:\n",
    "    - Qwen2.5-VL model with LoRA applied\n",
    "    - AdamW optimizer with HF scheduler\n",
    "    - Optional gradient checkpointing for VRAM savings\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_id,\n",
    "        lr,\n",
    "        weight_decay,\n",
    "        lr_scheduler_type,\n",
    "        warmup_steps,\n",
    "        num_training_steps,\n",
    "        adam_beta1=0.9,\n",
    "        adam_beta2=0.95,\n",
    "        adam_epsilon=1e-8,\n",
    "        gradient_checkpointing=True,\n",
    "        gc_use_reentrant=False,  # False avoids Qwen checkpointing bug\n",
    "        attn_implementation=\"eager\",\n",
    "        tf32=True,\n",
    "        lora_cfg=None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # Save all hparams including lora_cfg (except num_training_steps which is large/dynamic)\n",
    "        self.save_hyperparameters(ignore=[\"num_training_steps\"])\n",
    "        self.num_training_steps = num_training_steps\n",
    "\n",
    "        # Enable TensorFloat32 for faster matmul on Ampere+ GPUs\n",
    "        if tf32:\n",
    "            torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "        # Processor handles both text & image preprocessing\n",
    "        self.processor = AutoProcessor.from_pretrained(model_id, use_fast=True)\n",
    "\n",
    "        # Load Qwen base model in bf16 for memory savings\n",
    "        base_model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "            model_id,\n",
    "            torch_dtype=torch.bfloat16,\n",
    "            attn_implementation=attn_implementation,\n",
    "            device_map=\"auto\"\n",
    "        )\n",
    "\n",
    "        # --- Robust gradient checkpointing across Transformers versions ---\n",
    "        if gradient_checkpointing:\n",
    "            enabled = False\n",
    "            try:\n",
    "                # Newer API accepts kwargs dict\n",
    "                base_model.gradient_checkpointing_enable(\n",
    "                    gradient_checkpointing_kwargs={\"use_reentrant\": gc_use_reentrant}\n",
    "                )\n",
    "                enabled = True\n",
    "            except TypeError:\n",
    "                pass\n",
    "            if not enabled:\n",
    "                try:\n",
    "                    # Older API: no kwargs\n",
    "                    base_model.gradient_checkpointing_enable()\n",
    "                    enabled = True\n",
    "                except TypeError:\n",
    "                    # Very old fallbacks\n",
    "                    if hasattr(base_model, \"enable_gradient_checkpointing\"):\n",
    "                        base_model.enable_gradient_checkpointing()\n",
    "                        enabled = True\n",
    "                    elif hasattr(base_model, \"set_gradient_checkpointing\"):\n",
    "                        base_model.set_gradient_checkpointing(True)\n",
    "                        enabled = True\n",
    "            if hasattr(base_model, \"enable_input_require_grads\"):\n",
    "                base_model.enable_input_require_grads()\n",
    "        \n",
    "        # --- LoRA configuration from YAML ---\n",
    "        if not isinstance(lora_cfg, dict) or len(lora_cfg) == 0:\n",
    "            raise ValueError(\n",
    "                \"LoRA configuration is missing. Please provide a 'lora:' section in qwen2vl_config.yaml.\"\n",
    "            )\n",
    "        lora_config = LoraConfig(**lora_cfg)\n",
    "\n",
    "        # Get LoRA model\n",
    "        self.model = get_peft_model(base_model, lora_config)\n",
    "\n",
    "        # Training-friendly defaults\n",
    "        if hasattr(self.model, \"config\"):\n",
    "            self.model.config.use_cache = False\n",
    "            if getattr(self.model.config, \"pad_token_id\", None) is None:\n",
    "                self.model.config.pad_token_id = self.processor.tokenizer.eos_token_id\n",
    "\n",
    "    def forward(self, **batch):\n",
    "        return self.model(**batch)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        out = self(**batch)\n",
    "        # Log training loss per step (no epoch avg to match HF behavior)\n",
    "        self.log(\"train_loss\", out.loss, prog_bar=True, on_step=True, on_epoch=False)\n",
    "        return out.loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        out = self(**batch)\n",
    "        # Log validation loss averaged over an epoch\n",
    "        self.log(\"val_loss\", out.loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        return out.loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"\n",
    "        Set up:\n",
    "        - AdamW optimizer with HF's beta/eps/weight decay settings\n",
    "        - LR scheduler from transformers.optimization.get_scheduler\n",
    "        \"\"\"\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            self.model.parameters(),\n",
    "            lr=self.hparams.lr,\n",
    "            betas=(self.hparams.adam_beta1, self.hparams.adam_beta2),\n",
    "            eps=self.hparams.adam_epsilon,\n",
    "            weight_decay=self.hparams.weight_decay\n",
    "        )\n",
    "        scheduler = get_scheduler(\n",
    "            name=self.hparams.lr_scheduler_type,\n",
    "            optimizer=optimizer,\n",
    "            num_warmup_steps=self.hparams.warmup_steps,\n",
    "            num_training_steps=self.num_training_steps\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"interval\": \"step\",  # step-based scheduler like HF\n",
    "                \"frequency\": 1,\n",
    "                \"name\": \"lr\"\n",
    "            }\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a2638164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab09b58110b4603bf752885745cd7d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Module\n",
    "module = QwenLoraModule(\n",
    "    model_id=model_id,\n",
    "    lr=lr,\n",
    "    weight_decay=weight_decay,\n",
    "    lr_scheduler_type=lr_scheduler,\n",
    "    warmup_steps=warmup_steps,\n",
    "    num_training_steps=total_steps,\n",
    "    gradient_checkpointing=gradient_checkpointing,\n",
    "    gc_use_reentrant=gc_use_reentrant,\n",
    "    attn_implementation=\"eager\",\n",
    "    tf32=tf32,\n",
    "    lora_cfg=lora_cfg,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9e6d7a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hpc/mydata/yasin.senbabaoglu/anaconda/25.3.1/x86_64/envs/qwen2vl/lib/python3.11/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /hpc/mydata/yasin.senbabaoglu/anaconda/25.3.1/x86_64 ...\n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'SLURM_NODEID'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Trainer (Lightning: step-based val via val_check_interval)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m trainer = \u001b[43mpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccelerator\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevices\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprecision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgradient_clip_val\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlog_every_n_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogging_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mckpt_cb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_cb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad_batches\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_accum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mplugins\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mSLURMEnvironment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequeue_signal\u001b[49m\u001b[43m=\u001b[49m\u001b[43msignal\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSIGUSR1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_check_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# \"eval_strategy=steps\"\u001b[39;49;00m\n\u001b[32m     15\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m trainer.fit(module, train_loader, val_loader)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/hpc/mydata/yasin.senbabaoglu/anaconda/25.3.1/x86_64/envs/qwen2vl/lib/python3.11/site-packages/pytorch_lightning/utilities/argparse.py:70\u001b[39m, in \u001b[36m_defaults_from_env_vars.<locals>.insert_env_defaults\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     67\u001b[39m kwargs = \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mlist\u001b[39m(env_variables.items()) + \u001b[38;5;28mlist\u001b[39m(kwargs.items()))\n\u001b[32m     69\u001b[39m \u001b[38;5;66;03m# all args were already moved to kwargs\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/hpc/mydata/yasin.senbabaoglu/anaconda/25.3.1/x86_64/envs/qwen2vl/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:404\u001b[39m, in \u001b[36mTrainer.__init__\u001b[39m\u001b[34m(self, accelerator, strategy, devices, num_nodes, precision, logger, callbacks, fast_dev_run, max_epochs, min_epochs, max_steps, min_steps, max_time, limit_train_batches, limit_val_batches, limit_test_batches, limit_predict_batches, overfit_batches, val_check_interval, check_val_every_n_epoch, num_sanity_val_steps, log_every_n_steps, enable_checkpointing, enable_progress_bar, enable_model_summary, accumulate_grad_batches, gradient_clip_val, gradient_clip_algorithm, deterministic, benchmark, inference_mode, use_distributed_sampler, profiler, detect_anomaly, barebones, plugins, sync_batchnorm, reload_dataloaders_every_n_epochs, default_root_dir, model_registry)\u001b[39m\n\u001b[32m    401\u001b[39m \u001b[38;5;66;03m# init connectors\u001b[39;00m\n\u001b[32m    402\u001b[39m \u001b[38;5;28mself\u001b[39m._data_connector = _DataConnector(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m404\u001b[39m \u001b[38;5;28mself\u001b[39m._accelerator_connector = \u001b[43m_AcceleratorConnector\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevices\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccelerator\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccelerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m    \u001b[49m\u001b[43msync_batchnorm\u001b[49m\u001b[43m=\u001b[49m\u001b[43msync_batchnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbenchmark\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbenchmark\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_distributed_sampler\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_distributed_sampler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprecision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m    \u001b[49m\u001b[43mplugins\u001b[49m\u001b[43m=\u001b[49m\u001b[43mplugins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[38;5;28mself\u001b[39m._logger_connector = _LoggerConnector(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    417\u001b[39m \u001b[38;5;28mself\u001b[39m._callback_connector = _CallbackConnector(\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/hpc/mydata/yasin.senbabaoglu/anaconda/25.3.1/x86_64/envs/qwen2vl/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:163\u001b[39m, in \u001b[36m_AcceleratorConnector.__init__\u001b[39m\u001b[34m(self, devices, num_nodes, accelerator, strategy, plugins, precision, sync_batchnorm, benchmark, use_distributed_sampler, deterministic)\u001b[39m\n\u001b[32m    160\u001b[39m \u001b[38;5;28mself\u001b[39m.precision_plugin = \u001b[38;5;28mself\u001b[39m._check_and_init_precision()\n\u001b[32m    162\u001b[39m \u001b[38;5;66;03m# 6. Instantiate Strategy - Part 2\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_lazy_init_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/hpc/mydata/yasin.senbabaoglu/anaconda/25.3.1/x86_64/envs/qwen2vl/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:572\u001b[39m, in \u001b[36m_AcceleratorConnector._lazy_init_strategy\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    570\u001b[39m     \u001b[38;5;28mself\u001b[39m.strategy._layer_sync = \u001b[38;5;28mself\u001b[39m._layer_sync\n\u001b[32m    571\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.strategy, \u001b[33m\"\u001b[39m\u001b[33mset_world_ranks\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m572\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_world_ranks\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[38;5;28mself\u001b[39m.strategy._configure_launcher()\n\u001b[32m    575\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _IS_INTERACTIVE \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.strategy.launcher \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.strategy.launcher.is_interactive_compatible:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/hpc/mydata/yasin.senbabaoglu/anaconda/25.3.1/x86_64/envs/qwen2vl/lib/python3.11/site-packages/pytorch_lightning/strategies/ddp.py:210\u001b[39m, in \u001b[36mDDPStrategy.set_world_ranks\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mset_world_ranks\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    209\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cluster_environment \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m         \u001b[38;5;28mself\u001b[39m.cluster_environment.set_global_rank(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnode_rank\u001b[49m * \u001b[38;5;28mself\u001b[39m.num_processes + \u001b[38;5;28mself\u001b[39m.local_rank)\n\u001b[32m    211\u001b[39m         \u001b[38;5;28mself\u001b[39m.cluster_environment.set_world_size(\u001b[38;5;28mself\u001b[39m.num_nodes * \u001b[38;5;28mself\u001b[39m.num_processes)\n\u001b[32m    212\u001b[39m     \u001b[38;5;66;03m# `LightningEnvironment.set_global_rank` will do this too, but we cannot rely on that implementation detail\u001b[39;00m\n\u001b[32m    213\u001b[39m     \u001b[38;5;66;03m# additionally, for some implementations, the setter is a no-op, so it's safer to access the getter\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/hpc/mydata/yasin.senbabaoglu/anaconda/25.3.1/x86_64/envs/qwen2vl/lib/python3.11/site-packages/pytorch_lightning/strategies/parallel.py:63\u001b[39m, in \u001b[36mParallelStrategy.node_rank\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnode_rank\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mint\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcluster_environment\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnode_rank\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cluster_environment \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/hpc/mydata/yasin.senbabaoglu/anaconda/25.3.1/x86_64/envs/qwen2vl/lib/python3.11/site-packages/lightning_fabric/plugins/environments/slurm.py:155\u001b[39m, in \u001b[36mSLURMEnvironment.node_rank\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnode_rank\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mint\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSLURM_NODEID\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:679\u001b[39m, in \u001b[36m__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'SLURM_NODEID'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Trainer (Lightning: step-based val via val_check_interval)\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=epochs,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=devices,\n",
    "    precision=precision,\n",
    "    gradient_clip_val=1.0,\n",
    "    log_every_n_steps=logging_steps,\n",
    "    logger=logger,\n",
    "    callbacks=[ckpt_cb, lr_cb],\n",
    "    accumulate_grad_batches=grad_accum,\n",
    "    plugins=[SLURMEnvironment(requeue_signal=signal.SIGUSR1)],\n",
    "    strategy=strategy,\n",
    "    val_check_interval=eval_steps,  # \"eval_strategy=steps\"\n",
    ")\n",
    "\n",
    "trainer.fit(module, train_loader, val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dac5ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d637b8b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323bffb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d11c657",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a694eade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657a1b3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
